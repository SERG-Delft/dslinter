<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>data preparation on DSLinter - Linter for Machine Learning - Specific Code Smells</title>
    <link>https://hynn01.github.io/dslinter/tags/data-preparation/</link>
    <description>Recent content in data preparation on DSLinter - Linter for Machine Learning - Specific Code Smells</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://hynn01.github.io/dslinter/tags/data-preparation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>In Place APIs Misused</title>
      <link>https://hynn01.github.io/dslinter/code-smells/in-place-apis-misused/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/in-place-apis-misused/</guid>
      <description>Description “In-place operation is an operation that directly changes the content of a given linear algebra, vector, matrices (Tensor) without making a copy.” Due to the nature of the in-place operation, the in-place APIs are easily misused. Developers sometimes forget to set the in-place parameter in APIs to true while not assigning the new result to a variable, causing potential silent bugs. The data is not updated in this way, but the developer thinks it is and might not be able to find where the bug is.</description>
    </item>
    
    <item>
      <title>Unnecessary Iteration</title>
      <link>https://hynn01.github.io/dslinter/code-smells/unnecessary-iteration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/unnecessary-iteration/</guid>
      <description>Description &amp;ldquo;Vectorization is the process of converting an algorithm from operating on a single value at a time to operating on a set of values (vector) at one time.&amp;rdquo; ML applications are often data-intensive and need to apply an operation on a dataset. Therefore, it is better to adopt vectorized solution instead of iterating over data. As stated in the Pandas documentation : ”Iterating through pandas objects is generally slow. In many cases, iterating manually over the rows is not needed and can be avoided”.</description>
    </item>
    
    <item>
      <title>No Scaling Before Scaling-sensitive Operation</title>
      <link>https://hynn01.github.io/dslinter/code-smells/no-scaling-before-scaling-sensitive-operation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/no-scaling-before-scaling-sensitive-operation/</guid>
      <description>Description Principle Component Analysis (PCA) is used for finding the components that maximize the data&amp;rsquo;s variation and reduce its dimensions, which is an essential data processing method. Scaling is pretty crucial to PCA because of the way the principal components are calculated. If one variable is on a larger scale than another, it will dominate the PCA procedure. Similarly, there are some other scaling-sensitive operations. Support Vector Machine (SVM), Stochastic Gradient Descent (SGD), Multi-layer Perceptron classifier, L1 and L2 regularization are all sensitive to feature scaling.</description>
    </item>
    
    <item>
      <title>Data Leakage</title>
      <link>https://hynn01.github.io/dslinter/code-smells/data-leakage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/data-leakage/</guid>
      <description>Description &amp;ldquo;Data Leakage happens when the data you are using to train a machine learning algorithm happens to have the information you are trying to predict.&amp;rdquo; It results in overly optimistic performance during testing and poor performance in real-world usage. There are two main sources of data leakage: leaky predictors and a leaky validation strategy. Leaky predictors refer to the situation where some features updated or created after the target value is realized are included.</description>
    </item>
    
    <item>
      <title>Hyperparameter not Explicitly Set</title>
      <link>https://hynn01.github.io/dslinter/code-smells/hyperparameter-not-explicitly-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/hyperparameter-not-explicitly-set/</guid>
      <description>Description Hyperparameters are ML algorithm parameters used to control the learning process and are usually determined before the actual process starts. Hyperparameters should be set and tuned because they improve prediction quality and reproducibility. Tuning hyperparameters can lead to higher prediction quality because the default parameters of the learning algorithm may not be optimal for a given data or problem, and may lead to local optima. These parameters directly control the behavior of the training algorithm and therefore have a significant impact on the performance of the model.</description>
    </item>
    
    <item>
      <title>Nan Equality Misused</title>
      <link>https://hynn01.github.io/dslinter/code-smells/nan-equality-misused/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/nan-equality-misused/</guid>
      <description>Description While None == None evaluates to True, numpy.nan == numpy.nan evaluates to False. As Pandas treats None like numpy.nan for simplicity and performance reasons, a comparison of DataFrame elements with numpy.nan always return False . Therefore, developers need to be careful when using the NaN comparision in Numpy and Pandas. Otherwise, it may lead to unintentional behavior in the code.
Type API Specific
Existing Stage Data Preparation
Effect Error-prone</description>
    </item>
    
    <item>
      <title>Dataframe Coversion API Misused</title>
      <link>https://hynn01.github.io/dslinter/code-smells/dataframe-coversion-api-misused/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/code-smells/dataframe-coversion-api-misused/</guid>
      <description>Description When converting DataFrame to NumPy array, it is better to use df.to\_numpy() than df.values(). As noted in a post, df.values() has inconsistency problem. With .values it is unclear whether the returned value would be the actual array, some transformation of it, or one of the Pandas custom arrays. However, .values is not deprecated yet. Although the library developers note it as a warning in the documentation, it does not log a warning or error when compiling if we use .</description>
    </item>
    
    <item>
      <title>Regular Expression Solution Not Optimal</title>
      <link>https://hynn01.github.io/dslinter/deprecated/regular-expression-solution-not-optimal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/deprecated/regular-expression-solution-not-optimal/</guid>
      <description>Description A post provides a better coding solution for the regular expression, which might be able to apply to the Nature Language Processing (NLP) preprocessing process. NLP tasks are data-intensive and often take a long time to clean the data, so it would be good to save some time when preprocessing the data. The post noted that regex.sub() and str.translate() work faster than str.replace() in practice in Pandas library. The more efficient solution is worth considering.</description>
    </item>
    
    <item>
      <title>Tensor Shape Unset</title>
      <link>https://hynn01.github.io/dslinter/deprecated/tensor-shape-unset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/deprecated/tensor-shape-unset/</guid>
      <description>Description Several bugs can be caused by tensor unaligned. Usually, the unaligned tensor problems cannot be identified at the code level, but we can explicitly control one. It is recommended to explicitly set the shape of the input for tf.Variable() to make the tensor aligned. In this way, we can alleviate the unaligned tensor problem.
Type API Specific
Existing Stage Data Preparation
Effect Error-prone
Example ### TensorFlow import Tensorflow as tf # Violated Code normal_dist = tf.</description>
    </item>
    
    <item>
      <title>Backend Engine Mischoosed</title>
      <link>https://hynn01.github.io/dslinter/deprecated/backend-engine-mischoosed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/deprecated/backend-engine-mischoosed/</guid>
      <description>Description When using pd.eval() in Pandas library, the numexpr is optimized for performance and python options offer no performance benefit over numexpr. Generally, it is not recommended to set the parameter to python. The developers should be careful when explicitly set this parameter.
Type API Specific
Existing Stage Data Preparation
Effect Efficiency
Example ### Pandas import pandas as pd # Violated Code pd.eval(&amp;#39;df.A.str.contains(&amp;#34;ab&amp;#34;)&amp;#39;, engine=&amp;#39;python&amp;#39;) # Recommended Fix pd.eval(&amp;#39;df.A.str.contains(&amp;#34;ab&amp;#34;)&amp;#39;) Source: Paper Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.</description>
    </item>
    
  </channel>
</rss>
