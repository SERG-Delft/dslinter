<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>model training on DSLinter - Linter for Machine Learning - Specific Code Smells</title>
    <link>https://hynn01.github.io/dslinter/tags/model-training/</link>
    <description>Recent content in model training on DSLinter - Linter for Machine Learning - Specific Code Smells</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://hynn01.github.io/dslinter/tags/model-training/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hyperparameter not Explicitly Set</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/4-hyperparameter-not-explicitly-set/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/4-hyperparameter-not-explicitly-set/</guid>
      <description>Hyperparameters should be set explicitly.</description>
    </item>
    
    <item>
      <title>Memory not Freed</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/5-memory-not-freed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/5-memory-not-freed/</guid>
      <description>Free memory in time.</description>
    </item>
    
    <item>
      <title>Deterministic Algorithm Option Not Used</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/6-deterministic-algorithm-option-not-used/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/6-deterministic-algorithm-option-not-used/</guid>
      <description>Set deterministic algorithm option to &lt;code&gt;True&lt;/code&gt; during the development process, and use the option that provides better performance in the production.</description>
    </item>
    
    <item>
      <title>Missing the Mask of Invalid Value</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/7-missing-the-mask-of-invalid-value/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/7-missing-the-mask-of-invalid-value/</guid>
      <description>Add a mask for possible invalid values. For example, developers should add a mask for the input for &lt;code&gt;tf.log()&lt;/code&gt; API.</description>
    </item>
    
    <item>
      <title>Randomness Uncontrolled</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/8-randomness-uncontrolled/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/8-randomness-uncontrolled/</guid>
      <description>Set random seed explicitly during the development process whenever a possible random procedure is involved in the application.</description>
    </item>
    
    <item>
      <title>Broadcasting Feature Not Used</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/18-broadcasting-feature-not-used/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/18-broadcasting-feature-not-used/</guid>
      <description>Use the broadcasting feature in TensorFlow 2 to be more memory efficient.</description>
    </item>
    
    <item>
      <title>TensorArray Not Used</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/19-tensorarray-not-used/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/19-tensorarray-not-used/</guid>
      <description>Use &lt;code&gt;tf.TensorArray()&lt;/code&gt; in TensorFlow 2 if the value of the array will change in the loop.</description>
    </item>
    
    <item>
      <title>Pytorch Call Method Misused</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/20-pytorch-call-method-misused/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/20-pytorch-call-method-misused/</guid>
      <description>Use &lt;code&gt;self.net()&lt;/code&gt; in PyTorch to forward the input to the network instead of &lt;code&gt;self.net.forward()&lt;/code&gt;.</description>
    </item>
    
    <item>
      <title>Training / Evaluation Mode Improper Toggling</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/21-training-evaluation-mode-improper-toggling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/21-training-evaluation-mode-improper-toggling/</guid>
      <description>Call the training mode in the appropriate place in PyTorch code to avoid forgetting to toggle back the training mode after the inference step.</description>
    </item>
    
    <item>
      <title>Gradients Not Cleared before Backward Propagation</title>
      <link>https://hynn01.github.io/dslinter/posts/codesmells/22-gradients-not-cleared-before-backward-propagation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hynn01.github.io/dslinter/posts/codesmells/22-gradients-not-cleared-before-backward-propagation/</guid>
      <description>Use &lt;code&gt;optimizer.zero_grad()&lt;/code&gt;, &lt;code&gt;loss_fn.backward()&lt;/code&gt;, &lt;code&gt;optimizer.step()&lt;/code&gt; together in order in PyTorch. Do not forget to use &lt;code&gt;optimizer.zero_grad()&lt;/code&gt; before &lt;code&gt;loss_fn.backward()&lt;/code&gt; to clear gradients.</description>
    </item>
    
  </channel>
</rss>
