<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Missing the Mask of Invalid Value | DSLinter - Linter for Machine Learning - Specific Code Smells</title><meta name=keywords content="generic,model training,error-prone"><meta name=description content="Add a mask for possible invalid values. For example, developers should add a mask for the input for tf.log() API."><meta name=author content><link rel=canonical href=https://hynn01.github.io/dslinter/posts/codesmells/7-missing-the-mask-of-invalid-value/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/dslinter/assets/css/stylesheet.min.118d582b9317eeb0017c428ab7f64c4be58e68881aeb263d9b75c61866e244de.css integrity="sha256-EY1YK5MX7rABfEKKt/ZMS+WOaIga6yY9m3XGGGbiRN4=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/dslinter/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://hynn01.github.io/dslinter/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://hynn01.github.io/dslinter/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://hynn01.github.io/dslinter/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://hynn01.github.io/dslinter/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://hynn01.github.io/dslinter/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.96.0"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Missing the Mask of Invalid Value"><meta property="og:description" content="Add a mask for possible invalid values. For example, developers should add a mask for the input for tf.log() API."><meta property="og:type" content="article"><meta property="og:url" content="https://hynn01.github.io/dslinter/posts/codesmells/7-missing-the-mask-of-invalid-value/"><meta property="article:section" content="posts"><meta property="og:site_name" content="DSLinter - Linter for Machine Learning Application - Specific Code Smells"><meta name=twitter:card content="summary"><meta name=twitter:title content="Missing the Mask of Invalid Value"><meta name=twitter:description content="Add a mask for possible invalid values. For example, developers should add a mask for the input for tf.log() API."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://hynn01.github.io/dslinter/posts/"},{"@type":"ListItem","position":2,"name":"Code Smells","item":"https://hynn01.github.io/dslinter/posts/codesmells/"},{"@type":"ListItem","position":3,"name":"Missing the Mask of Invalid Value","item":"https://hynn01.github.io/dslinter/posts/codesmells/7-missing-the-mask-of-invalid-value/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Missing the Mask of Invalid Value","name":"Missing the Mask of Invalid Value","description":"Add a mask for possible invalid values. For example, developers should add a mask for the input for tf.log() API.","keywords":["generic","model training","error-prone"],"articleBody":"Description Context In deep learning, the value of the variable changes during training. The variable may turn into an invalid value for another operation in this process.\nProblem Several posts on Stack Overflow talk about the bugs that are not easy to discover caused by the input of the log function approaching zero. In this kind of program, the input variable turns to zero and becomes an invalid value for tf.log(), which raises an error during the training process. However, the error’s stack trace did not directly point to the line of code that the bug exists. This problem is not easy to debug and may take a long training time to find.\nSolution The developer should check the input for tf.log() API and add a mask to avoid the invalid value. For example, developer can change tf.log(x) to tf.log(tf.clip_by_value(x,1e-10,1.0)). If the value of x becomes zero, i.e., lower than the lowest bound 1e-10, the tf.clip_by_value() API will act as a mask and outputs 1e-10. The same applies to other invalid value situations. It will save time and effort if the developer could identify this smell before the code run into errors.\nType Generic\nExisting Stage Model Training\nEffect Error-prone\nExample ### TensorFlow 1.x from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) sess = tf.InteractiveSession()  def weight_variable(shape):  initial = tf.truncated_normal(shape, stddev=0.1)  return tf.Variable(initial)  def bias_Variable(shape):  initial = tf.constant(0.1, shape=shape)  return tf.Variable(initial)  def conv2d(x, W):  return tf.nn.conv2d(x, W, strides=[1,1,1,1],padding=\"SAME\")  def max_pool_2x2(x):  return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1],padding=\"SAME\")  x = tf.placeholder(tf.float32, [None, 784]) y_ = tf.placeholder(tf.float32, [None, 10])  x_image = tf.reshape(x, [-1, 28, 28, 1])  W_conv1 = weight_variable([5,5,1,32]) b_conv1 = bias_Variable([32]) h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) h_pool1 = max_pool_2x2(h_conv1)  W_conv2 = weight_variable([5,5,32,64]) b_conv2 = bias_Variable([64]) h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2) h_pool2 = max_pool_2x2(h_conv2)  W_fc1 = weight_variable([7*7*64,1024]) b_fc1 = bias_Variable([1024]) h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64]) h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)  keep_prob = tf.placeholder(tf.float32) h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)  W_fc2 = weight_variable([1024,10]) b_fc2 = bias_Variable([10]) y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)  - cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),reduction_indices=[1])) + cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(tf.clip_by_value(y_conv,1e-10,1.0)),reduction_indices=[1])) train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)  correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))  tf.global_variables_initializer().run()  for i in range(20000):  batch = mnist.train.next_batch(50)  if i % 100 == 0:  train_accuracy = accuracy.eval(feed_dict = {x:batch[0] , y_:batch[1], keep_prob: 1.0})  print(\"step %d,train accuracy %g\"%(i,train_accuracy))  train_step.run(feed_dict = {x:batch[0] , y_:batch[1], keep_prob: 0.5})  print(\"test accuracy %g\"%accuracy.eval(feed_dict = {x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0})) Source: Paper  Nargiz Humbatova, Gunel Jahangirova, Gabriele Bavota, Vincenzo Riccio, AndreaStocco, and Paolo Tonella. 2020. Taxonomy of real faults in deep learning sys-tems. InProceedings of the ACM/IEEE 42nd International Conference on SoftwareEngineering. 1110–1121. Yuhao Zhang, Yifan Chen, Shing-Chi Cheung, Yingfei Xiong, and Lu Zhang. 2018.An empirical study on TensorFlow program bugs. InProceedings of the 27th ACMSIGSOFT International Symposium on Software Testing and Analysis. 129–140.  Grey Literature GitHub Commit Stack Overflow  https://stackoverflow.com/questions/33712178/tensorflow-nan-bug https://stackoverflow.com/questions/33699174/tensorflows-relugrad-claims-input-is-not-finite https://stackoverflow.com/questions/39487825/tensorflow-convolutionary-net-grayscale-vs-black-white-training https://stackoverflow.com/questions/35078027/implement-mlp-in-tensorflow  Documentation ","wordCount":"447","inLanguage":"en","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://hynn01.github.io/dslinter/posts/codesmells/7-missing-the-mask-of-invalid-value/"},"publisher":{"@type":"Organization","name":"DSLinter - Linter for Machine Learning - Specific Code Smells","logo":{"@type":"ImageObject","url":"https://hynn01.github.io/dslinter/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://hynn01.github.io/dslinter/ accesskey=h title="DSLinter - Linter for Machine Learning - Specific Code Smells (Alt + H)">DSLinter - Linter for Machine Learning - Specific Code Smells</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://hynn01.github.io/dslinter/posts/codesmells/ title="Code Smells"><span>Code Smells</span></a></li><li><a href=https://hynn01.github.io/dslinter/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://hynn01.github.io/dslinter/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://hynn01.github.io/dslinter/>Home</a>&nbsp;»&nbsp;<a href=https://hynn01.github.io/dslinter/posts/>Posts</a>&nbsp;»&nbsp;<a href=https://hynn01.github.io/dslinter/posts/codesmells/>Code Smells</a></div><h1 class=post-title>Missing the Mask of Invalid Value</h1><div class=post-meta></div></header><div class=post-content><h3 id=description>Description<a hidden class=anchor aria-hidden=true href=#description>#</a></h3><h4 id=context>Context<a hidden class=anchor aria-hidden=true href=#context>#</a></h4><p>In deep learning, the value of the variable changes during training. The variable may turn into an invalid value for another operation in this process.</p><h4 id=problem>Problem<a hidden class=anchor aria-hidden=true href=#problem>#</a></h4><p>Several posts on Stack Overflow talk about the bugs that are not easy to discover caused by the input of the log function approaching zero. In this kind of program, the input variable turns to zero and becomes an invalid value for <code>tf.log()</code>, which raises an error during the training process. However, the error&rsquo;s stack trace did not directly point to the line of code that the bug exists. This problem is not easy to debug and may take a long training time to find.</p><h4 id=solution>Solution<a hidden class=anchor aria-hidden=true href=#solution>#</a></h4><p>The developer should check the input for <code>tf.log()</code> API and add a mask to avoid the invalid value. For example, developer can change <code>tf.log(x)</code> to <code>tf.log(tf.clip_by_value(x,1e-10,1.0))</code>. If the value of <code>x</code> becomes zero, i.e., lower than the lowest bound 1e-10, the <code>tf.clip_by_value()</code> API will act as a mask and outputs 1e-10. The same applies to other invalid value situations. It will save time and effort if the developer could identify this smell before the code run into errors.</p><h3 id=type>Type<a hidden class=anchor aria-hidden=true href=#type>#</a></h3><p>Generic</p><h3 id=existing-stage>Existing Stage<a hidden class=anchor aria-hidden=true href=#existing-stage>#</a></h3><p>Model Training</p><h3 id=effect>Effect<a hidden class=anchor aria-hidden=true href=#effect>#</a></h3><p>Error-prone</p><h3 id=example>Example<a hidden class=anchor aria-hidden=true href=#example>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>### TensorFlow 1.x
</span></span><span style=display:flex><span>from tensorflow.examples.tutorials.mnist import input_data
</span></span><span style=display:flex><span>import tensorflow as tf
</span></span><span style=display:flex><span>mnist = input_data.read_data_sets(&#34;MNIST_data/&#34;, one_hot=True)
</span></span><span style=display:flex><span>sess = tf.InteractiveSession()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>def weight_variable(shape):
</span></span><span style=display:flex><span>    initial = tf.truncated_normal(shape, stddev=0.1)
</span></span><span style=display:flex><span>    return tf.Variable(initial)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>def bias_Variable(shape):
</span></span><span style=display:flex><span>    initial = tf.constant(0.1, shape=shape)
</span></span><span style=display:flex><span>    return tf.Variable(initial)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>def conv2d(x, W):
</span></span><span style=display:flex><span>    return tf.nn.conv2d(x, W, strides=[1,1,1,1],padding=&#34;SAME&#34;)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>def max_pool_2x2(x):
</span></span><span style=display:flex><span>    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1],padding=&#34;SAME&#34;)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>x = tf.placeholder(tf.float32, [None, 784])
</span></span><span style=display:flex><span>y_ = tf.placeholder(tf.float32, [None, 10])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>x_image = tf.reshape(x, [-1, 28, 28, 1])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>W_conv1 = weight_variable([5,5,1,32])
</span></span><span style=display:flex><span>b_conv1 = bias_Variable([32])
</span></span><span style=display:flex><span>h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)
</span></span><span style=display:flex><span>h_pool1 = max_pool_2x2(h_conv1)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>W_conv2 = weight_variable([5,5,32,64])
</span></span><span style=display:flex><span>b_conv2 = bias_Variable([64])
</span></span><span style=display:flex><span>h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)
</span></span><span style=display:flex><span>h_pool2 = max_pool_2x2(h_conv2)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>W_fc1 = weight_variable([7*7*64,1024])
</span></span><span style=display:flex><span>b_fc1 = bias_Variable([1024])
</span></span><span style=display:flex><span>h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])
</span></span><span style=display:flex><span>h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>keep_prob = tf.placeholder(tf.float32)
</span></span><span style=display:flex><span>h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>W_fc2 = weight_variable([1024,10])
</span></span><span style=display:flex><span>b_fc2 = bias_Variable([10])
</span></span><span style=display:flex><span>y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>- cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y_conv),reduction_indices=[1]))
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+ cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(tf.clip_by_value(y_conv,1e-10,1.0)),reduction_indices=[1]))
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))
</span></span><span style=display:flex><span>accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>tf.global_variables_initializer().run()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>for i in range(20000):
</span></span><span style=display:flex><span>    batch = mnist.train.next_batch(50)
</span></span><span style=display:flex><span>    if i % 100 == 0:
</span></span><span style=display:flex><span>        train_accuracy = accuracy.eval(feed_dict = {x:batch[0] , y_:batch[1], keep_prob: 1.0})
</span></span><span style=display:flex><span>        print(&#34;step %d,train accuracy %g&#34;%(i,train_accuracy))
</span></span><span style=display:flex><span>    train_step.run(feed_dict = {x:batch[0] , y_:batch[1], keep_prob: 0.5})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(&#34;test accuracy %g&#34;%accuracy.eval(feed_dict = {x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0}))
</span></span></code></pre></div><h3 id=source>Source:<a hidden class=anchor aria-hidden=true href=#source>#</a></h3><h4 id=paper>Paper<a hidden class=anchor aria-hidden=true href=#paper>#</a></h4><ul><li>Nargiz Humbatova, Gunel Jahangirova, Gabriele Bavota, Vincenzo Riccio, AndreaStocco, and Paolo Tonella. 2020. Taxonomy of real faults in deep learning sys-tems. InProceedings of the ACM/IEEE 42nd International Conference on SoftwareEngineering. 1110–1121.</li><li>Yuhao Zhang, Yifan Chen, Shing-Chi Cheung, Yingfei Xiong, and Lu Zhang. 2018.An empirical study on TensorFlow program bugs. InProceedings of the 27th ACMSIGSOFT International Symposium on Software Testing and Analysis. 129–140.</li></ul><h4 id=grey-literature>Grey Literature<a hidden class=anchor aria-hidden=true href=#grey-literature>#</a></h4><h4 id=github-commit>GitHub Commit<a hidden class=anchor aria-hidden=true href=#github-commit>#</a></h4><h4 id=stack-overflow>Stack Overflow<a hidden class=anchor aria-hidden=true href=#stack-overflow>#</a></h4><ul><li><a href=https://stackoverflow.com/questions/33712178/tensorflow-nan-bug>https://stackoverflow.com/questions/33712178/tensorflow-nan-bug</a></li><li><a href=https://stackoverflow.com/questions/33699174/tensorflows-relugrad-claims-input-is-not-finite>https://stackoverflow.com/questions/33699174/tensorflows-relugrad-claims-input-is-not-finite</a></li><li><a href=https://stackoverflow.com/questions/39487825/tensorflow-convolutionary-net-grayscale-vs-black-white-training>https://stackoverflow.com/questions/39487825/tensorflow-convolutionary-net-grayscale-vs-black-white-training</a></li><li><a href=https://stackoverflow.com/questions/35078027/implement-mlp-in-tensorflow>https://stackoverflow.com/questions/35078027/implement-mlp-in-tensorflow</a></li></ul><h4 id=documentation>Documentation<a hidden class=anchor aria-hidden=true href=#documentation>#</a></h4></div><footer class=post-footer><ul class=post-tags><li><a href=https://hynn01.github.io/dslinter/tags/generic/>generic</a></li><li><a href=https://hynn01.github.io/dslinter/tags/model-training/>model training</a></li><li><a href=https://hynn01.github.io/dslinter/tags/error-prone/>error-prone</a></li></ul><nav class=paginav><a class=prev href=https://hynn01.github.io/dslinter/posts/codesmells/6-deterministic-algorithm-option-not-used/><span class=title>« Prev Page</span><br><span>Deterministic Algorithm Option Not Used</span></a>
<a class=next href=https://hynn01.github.io/dslinter/posts/codesmells/8-randomness-uncontrolled/><span class=title>Next Page »</span><br><span>Randomness Uncontrolled</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://hynn01.github.io/dslinter/>DSLinter - Linter for Machine Learning - Specific Code Smells</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>